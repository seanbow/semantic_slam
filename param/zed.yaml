## Calibration information

# Intrinsics
cam_model: Pinhole
cam_height: 720
cam_width: 1280
cam_fx: 679.6778564453125
cam_fy: 679.6778564453125
cam_cx: 637.9580078125
cam_cy: 354.5067138671875
cam_d0: 0.0
cam_d1: 0.0
cam_d2: 0.0
cam_d3: 0.0

### Extrinsics between robot body (frame "I" for IMU) and camera ("C")

I_p_C: [0.0, 0.03, 0.0]
I_q_C: [-0.500, 0.500, -0.500, 0.500]

## Optimization parameters
covariance_delay: 5.0
max_optimization_time: 1.0
loop_closure_threshold: 10 # in number of keyframes
smoothing_length: 50

verbose_optimization: true
use_manual_elimination_ordering: false

## IMU/body info / calibration


## Feature_tracker parameters
ransac_iterations: 25      # number of iterations in essential matrix estimating ransac loop
feature_spacing: 5         # minimum pixel distance between extracted features. i.e. an upper bound of sorts on feature density
max_features_per_im: 50    # maximum number of features to keep per image
sqrt_samp_thresh: 0.01      # Threshold on inliers in sampson error, higher = more permissive
tracking_framerate: 4     # drops images so tracking is performed at this framerate

## Semslam parameters

odometry_type: "external"   # odometry is handled by the zed, so "external"

### Geometric feature parameters
include_geometric_features: true
reprojection_error_threshold: 8 
use_smart_projection_factors: true

### Semantic measurement parameters
keypoint_msmt_sigma: 15                 # keypoint measurement sigma (pixels)
keypoint_initialization_depth_sigma: 2  # meters

min_object_n_keypoints: 4               # minimum number of observed keypoints needed to consider an object good and include it in the factor graph
min_landmark_observations: 4           # minimum number of observations needed for a keypoint before estimating depth and including in optimization
min_observed_keypoints_to_initialize: 4 

keyframe_translation_threshold: 0.05
keyframe_translation_without_measurement_threshold: 0.05
keyframe_rotation_threshold: 5 # degrees
keyframe_rotation_without_measurement_threshold: 5

### Semantic object optimization parameters
structure_regularization_factor: 10     # lambda in structure optimization term lambda * ||c||^2
robust_estimator_parameter: 1.5
include_objects_in_graph: true

# Error in the structure factor due to misalignment is defined as 
# || L - R*S - t ||_W
# where W = (1/structure_error_coefficient) * I
# i.e. this is an inverse "noise" like value where higher = more penalty for 
# deviations from the calculated object structure
structure_error_coefficient: 500

keypoint_activation_threshold: 0.4     # threshold above which to consider a keypoint observed

camera_range: 4                      # meters

mahal_thresh_assign: 4                  # Mahalanobis distance below which to assign data (MLDataAssociator)
loop_closure_mahal_thresh: 3            # used in place of mahal_thresh_assign if an assignment would trigger a loop closure
mahal_thresh_init: 25                   # Mahalanobis distance above which to assign new mapped landmarks (MLDataAssociator)

max_new_factor_error: 300

constraint_weight_threshold: 0.8        # if the weight of a constraint (i.e., an object measurement) is less than this do not incorporate the keypoint measurements corresponding to this object
new_landmark_weight_threshold: 0.9      # if the weight of the last column in the weights matrix for a measurement is greater than this value, add a new object to the estimated_objects_ vector

## Object classes
model_names: ["gascan", "chair", "pelican", "tableclosed", "cart", "ladder"]
model_directory: "/home/kodlab/catkin_ws/src/object_pose_detection/semslam/semslam/models/objects/"

gravity: [0, 0, -9.81]

init_p: [0, 0, 0]
init_p_sigma: [1.0e-7, 1.0e-7, 1.0e-7]

init_q: [0, 0, 0, 1]
init_q_sigma: [0.02, 0.02, 0.02]

## Visualization
geometric_point_scale: 0.05
object_keypoint_scale: 0.1
show_object_labels: false
trajectory_width: 0.05
covisibility_width: 0.05
draw_semantic_covisibility: true
draw_geometric_covisibility: true
color_smoothing_window: true
